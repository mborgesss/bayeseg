{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/home/paulo/git/bayeseg')\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from SeqSeg.SeqSeg import SeqSeg\n",
    "\n",
    "savefolder = '/home/paulo/git/bayeseg/Output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing time for various time resolutions\n",
    "\n",
    "Note: the cell below replicates the results reported on Table 1, p. 11 of the paper. However, the replication is not exact, since the computing times depend on uncontrollable factors (such as system's architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comparison cannot be made to be exact with the results in the paper, since it depends \n",
    "# on the system's characteristics and on other software that might be possibly running simultaneously\n",
    "\n",
    "ss = SeqSeg()\n",
    "\n",
    "\n",
    "sizes = [10000, 100000, 1000000]\n",
    "tres = [1, 10, 100, 1000]\n",
    "\n",
    "ss.initialize(1, 0.1, 100, 200, 1)\n",
    "result = []\n",
    "np.random.seed(123456)\n",
    "for size in sizes:\n",
    "    signal = np.random.normal(0, 1, [size, 1])\n",
    "    ss.feed_data(signal)\n",
    "    for res in tres:\n",
    "        t, tdur = ss.segments(minlen = 1000000, res = res, verbose = False)\n",
    "        print(\"Size = \" + str(size) + \", tres = \" + str(res) + \", t = \", str(tdur))\n",
    "        result.append([size, res, tdur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final, columns = ['nsignal', 'stdnoise', 'delta', 'mciter', 'minev', 'maxev', 'accavg', 'dhat', 'shat', 'dRhat', 'sRhat'])\n",
    "\n",
    "# Generate latex code\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing convergence of MCMC method for evidence value calculation\n",
    "\n",
    "Note: the cells below replicate the results reported on Table 2, p. 13 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cposterior_full(d, s, Nw, N2, beta, sum1, sum2):\n",
    "    ''' Full log-posterior kernel for MCMC sampling\n",
    "\n",
    "        Arguments:\n",
    "\n",
    "        d - current value for delta\n",
    "        s - current value for sigma\n",
    "        Nw - total signal size\n",
    "        N2 - size of second segment\n",
    "        beta - parameter for laplace prior\n",
    "        sum1 - sum of amplitudes squared for first segment\n",
    "        sum2 - sum of amplitudes squared for second segment\n",
    "    '''\n",
    "    \n",
    "    if d <= 0 or s <= 0:\n",
    "        return -1e+308\n",
    "    \n",
    "    # Jeffreys' prior for sigma\n",
    "    dpriors = -np.log(s)\n",
    "\n",
    "    # Laplace prior for delta\n",
    "    dpriord = -np.log(beta) - abs(d-1)/beta\n",
    "\n",
    "    post = dpriord +  dpriors - Nw*np.log(s)-0.5*N2*np.log(d)\n",
    "    post = post - sum1/(2*(s**2)) - sum2/(2*d*(s**2))\n",
    "\n",
    "    return post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc(p0, mcburn, mciter, beta, N, N2, sum1, sum2):\n",
    "    ''' Run MCMC\n",
    "\n",
    "        Arguments:\n",
    "\n",
    "        mcburn - burn-in period for chain\n",
    "        mciter - number of points to sample\n",
    "        p0 - posterior under H0\n",
    "        beta - parameter for Laplace prior\n",
    "        N - total signal size\n",
    "        N2 - size of second segment\n",
    "        sum1 - sum of amplitude squared for the first segment\n",
    "        sum2 - sum of amplitude squared for the second segment\n",
    "\n",
    "    '''\n",
    "    \n",
    "    dcur = (sum2 / (N2-1))/(sum1 / (N-N2-1))\n",
    "    scur = np.sqrt(sum1 / (N-N2-1))\n",
    "\n",
    "    # Standard deviations and covariance for random-walk candidates distributions\n",
    "    dvar = (dcur / 3) ** 2\n",
    "    svar = (scur / 3) ** 2\n",
    "    cov = 0.0\n",
    "    \n",
    "    dcur = abs(dcur + np.random.normal(0, dvar))\n",
    "    scur = abs(scur + np.random.normal(0, svar))\n",
    "\n",
    "    pcur = cposterior_full(dcur, scur, N, N2, beta, sum1, sum2)\n",
    "    \n",
    "    \n",
    "    # Parameters for adaptive MH\n",
    "    sd = (2.4*2.4)/2.0\n",
    "    eps = 1e-30\n",
    "\n",
    "    # Starting point for adaptive MH\n",
    "    t0 = 500\n",
    "    \n",
    "    dmean = 0.0\n",
    "    smean = 0.0\n",
    "    sumdsq = 0.0\n",
    "    sumssq = 0.0\n",
    "    cov0 = 0.0\n",
    "    accept = 0\n",
    "    for i in range(t0):\n",
    "        \n",
    "        # Generate candidates\n",
    "        u1 = np.random.normal(0, 1)\n",
    "        dcand = dcur + u1*np.sqrt(dvar)\n",
    "        \n",
    "        if dcand > 0:\n",
    "            # Calculates full posterior\n",
    "            pcand = cposterior_full(dcand, scur, N, N2, beta, sum1, sum2)\n",
    "\n",
    "            # Acceptance ratio\n",
    "            #a = Exp(pcand - pcur) * Exp(scand - scur)\n",
    "            a = (pcand - pcur)\n",
    "\n",
    "            if np.log(np.random.uniform()) < a:\n",
    "                dcur = dcand\n",
    "                pcur = pcand\n",
    "                accept = accept + 1\n",
    "            #endif        \n",
    "        \n",
    "        u2 = np.random.normal(0, 1)\n",
    "        scand = abs(scur + np.sqrt(svar)*u2)\n",
    "        \n",
    "        if scand > 0:\n",
    "            # Calculates full posterior\n",
    "            pcand = cposterior_full(dcur, scand, N, N2, beta, sum1, sum2)\n",
    "\n",
    "            # Acceptance ratio\n",
    "            #a = Exp(pcand - pcur) * Exp(scand - scur)\n",
    "            a = (pcand - pcur)\n",
    "\n",
    "            if np.log(np.random.uniform()) < a:\n",
    "                scur = scand\n",
    "                pcur = pcand\n",
    "                accept = accept + 1\n",
    "            #endif\n",
    "        \n",
    "        dmean = dmean + dcur \n",
    "        smean = smean + scur\n",
    "        cov0 = cov0 + dcur*scur \n",
    "        sumdsq = sumdsq + dcur*dcur \n",
    "        sumssq = sumssq + scur*scur \n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "    assert accept > 0\n",
    "    tmp = dmean*dmean/t0\n",
    "    tmp = sumdsq - tmp\n",
    "    dvar = tmp/(t0-1.0)\n",
    "    tmp = smean*smean/t0\n",
    "    tmp = sumssq - tmp\n",
    "    svar = tmp/(t0-1.0)\n",
    "    \n",
    "    if svar < 0:\n",
    "        print(accept)\n",
    "        print((smean*smean)/t0)\n",
    "        print([sumssq, smean, t0])\n",
    "        print(svar)\n",
    "    \n",
    "    cov = (1/(t0-1))*(cov0 - dmean*smean/t0)\n",
    "    rho = cov/(np.sqrt(dvar*svar))\n",
    "    dmean = dmean / t0\n",
    "    smean = smean / t0    \n",
    "    t = t0\n",
    "\n",
    "    accept = 0\n",
    "    for i in range(mcburn):\n",
    "        \n",
    "        # Generate candidates\n",
    "        u1 = np.random.normal(0, 1)\n",
    "        u2 = np.random.normal(0, 1)\n",
    "        if abs(rho) > 1:\n",
    "            print([dvar, svar, cov])\n",
    "            assert abs(rho) <= 1\n",
    "        u2 = rho * u1 + (1 - rho) * u2\n",
    "        \n",
    "        dcand = dcur + u1*np.sqrt(dvar)\n",
    "        #scand = scur + (cov/np.sqrt(dvar))*u1 + np.sqrt(svar - (cov*cov)/(dvar))*u2\n",
    "        scand = scur + u2*np.sqrt(svar)\n",
    "        \n",
    "        if dcand > 0 and scand > 0:\n",
    "            # Calculates full posterior\n",
    "            pcand = cposterior_full(dcand, scand, N, N2, beta, sum1, sum2)\n",
    "\n",
    "            # Acceptance ratio\n",
    "            #a = Exp(pcand - pcur) * Exp(scand - scur)\n",
    "            a = (pcand - pcur)\n",
    "\n",
    "            if np.log(np.random.uniform()) < a:\n",
    "                scur = scand\n",
    "                dcur = dcand\n",
    "                pcur = pcand\n",
    "                accept = accept + 1\n",
    "            #endif\n",
    "            \n",
    "        # Updating covariance matrix\n",
    "        dmeanant = dmean\n",
    "        smeanant = smean\n",
    "        dmean = (t*dmeanant + dcur) / (t + 1)\n",
    "        smean = (t*smeanant + scur) / (t + 1)            \n",
    "        dvar =  ((t-1.0)*dvar)/t + (sd/t)*(t*dmeanant*dmeanant - (t+1)*dmean*dmean + dcur*dcur + eps)\n",
    "        \n",
    "        if ((t-1.0)*svar)/t + (sd/t)*(t*smeanant*smeanant - (t+1)*smean*smean + scur*scur + eps) < 0:\n",
    "            print([t, svar, sd, smeanant, smean, scur, eps])        \n",
    "        \n",
    "        svar =  ((t-1.0)*svar)/t + (sd/t)*(t*smeanant*smeanant - (t+1)*smean*smean + scur*scur + eps)\n",
    "        cov = ((t-1.0)*cov)/t + (sd/t)*(t*dmeanant*smeanant - (t+1)*dmean*smean + dcur*scur)\n",
    "\n",
    "        rho = cov/(np.sqrt(dvar*svar))\n",
    "        t = t + 1\n",
    "        assert dvar > 0\n",
    "        assert svar > 0\n",
    "            \n",
    "    #endfor\n",
    "\n",
    "    accept = 0\n",
    "    ev = 0\n",
    "    sample = []\n",
    "    for i in range(mciter):\n",
    "        # Generate candidates\n",
    "        u1 = np.random.normal(0, 1)\n",
    "        u2 = np.random.normal(0, 1)\n",
    "        u2 = rho*u1 + (1-rho)*u2\n",
    "        \n",
    "        dcand = dcur + u1*np.sqrt(dvar)\n",
    "        #scand = scur + (cov/np.sqrt(dvar))*u1 + np.sqrt(svar - (cov*cov)/(dvar))*u2\n",
    "        scand = scur + np.sqrt(svar)*u2\n",
    "\n",
    "        if dcand > 0 and scand > 0:\n",
    "            # Calculates full posterior\n",
    "            pcand = cposterior_full(dcand, scand, N, N2, beta, sum1, sum2)\n",
    "\n",
    "            # Acceptance ratio\n",
    "            a = pcand - pcur\n",
    "\n",
    "            if np.log(np.random.uniform()) < a:\n",
    "                dcur = dcand\n",
    "                scur = scand\n",
    "                pcur = pcand\n",
    "                accept = accept + 1\n",
    "            #endif\n",
    "        sample.append([dcur, scur])\n",
    "        if pcur > p0:\n",
    "            ev = ev + 1\n",
    "    \n",
    "    ev = 1 - ev / mciter\n",
    "\n",
    "    return sample, ev, accept / mciter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simulates signal: one change point\n",
    "n1 = 500000\n",
    "n2 = 500000\n",
    "N = n1 + n2\n",
    "stdnoise = [1]\n",
    "delta = [1, 1.1, 1.5]\n",
    "\n",
    "mciter = [1000, 10000, 100000]\n",
    "beta = 1\n",
    "\n",
    "M = 4\n",
    "final = []\n",
    "cont = 0\n",
    "total = len(stdnoise) * len(delta) * len(mciter) \n",
    "\n",
    "# Set random seed for replication purposes\n",
    "np.random.seed(123456)\n",
    "for sn in stdnoise:\n",
    "    for d in delta:\n",
    "        signal = np.concatenate([np.random.normal(0, sn, [n1, 1]), np.random.normal(0, np.sqrt(d)*sn, [n2, 1])])\n",
    "        sum1 = sum(signal[:n1]**2)\n",
    "        sum2 = sum(signal[n1:]**2)\n",
    "        s0 = np.sqrt((sum1 + sum2)/(N + 1.))\n",
    "        p0 = cposterior_full(1.0, s0, N, n2, beta, sum1, sum2)\n",
    "        for mn in mciter:\n",
    "            measures = []\n",
    "            for i in range(M):\n",
    "                sample, ev, acc = mcmc(p0, mn, mn, beta, n1+n2, n2, sum1, sum2)\n",
    "                dsample = np.asarray([s[0] for s in sample])\n",
    "                ssample = np.asarray([s[1] for s in sample])\n",
    "                davg = dsample.mean()\n",
    "                savg = ssample.mean()\n",
    "                dvar = dsample.var()*(mn/(mn-1))\n",
    "                svar = ssample.var()*(mn/(mn-1))\n",
    "                measures.append([davg, savg, dvar, svar, ev, acc])\n",
    "                \n",
    "            minev = min([m[4] for m in measures])\n",
    "            maxev = max([m[4] for m in measures])\n",
    "            dhat = (1/M)*sum([m[0] for m in measures])\n",
    "            shat = (1/M)*sum([m[1] for m in measures])\n",
    "            dB = (1 / (M-1))*sum([(m[0] - dhat)**2 for m in measures])\n",
    "            sB = (1 / (M-1))*sum([(m[1] - shat)**2 for m in measures])\n",
    "            dW = (1/M)*sum([m[2] for m in measures])\n",
    "            sW = (1/M)*sum([m[3] for m in measures])\n",
    "            accavg = (1/M)*sum([m[5] for m in measures])\n",
    "            dVhat = (mn-1)/mn * dW + dB + dB / M\n",
    "            sVhat = (mn-1)/mn * sW + sB + sB / M\n",
    "            dRhat = dVhat / dW\n",
    "            sRhat = sVhat / sW\n",
    "            final.append([n1, sn, d, mn, minev, maxev, accavg, dhat, shat, dRhat, sRhat])\n",
    "            print(\"Run \" + str(cont+1) + \" of \" + str(total))\n",
    "            cont = cont + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing $\\alpha = 0.1$, several values of $\\beta$\n",
    "\n",
    "Note: the cell below replicates the results reported on Table 3, p. 13 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "deltalist = [1, 1.1, 1.5]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 20000\n",
    "mcburn = 10000\n",
    "alphalist = [0.1]\n",
    "betalist = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "nruns = 30\n",
    "\n",
    "# replicate = True to replicate results\n",
    "ss = SeqSeg(replicate = True)\n",
    "res = []\n",
    "\n",
    "np.random.seed(123456)\n",
    "\n",
    "for delta in deltalist:\n",
    "    # Simulates signal\n",
    "    signal = np.random.normal(0, 1, [npoints, 1])\n",
    "    for i in range(len(cuts)):\n",
    "        if (i+1)%2:\n",
    "            signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta))\n",
    "    ss.feed_data(signal)\n",
    "    for beta in betalist:\n",
    "        for alpha in alphalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "            nsegmean = 0\n",
    "            minseg = 500000\n",
    "            maxseg = 0\n",
    "            tmean = 0\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 5000, res = 100, verbose = False)\n",
    "                nsegmean = nsegmean + (len(t)+1)/nruns\n",
    "                tmean = tmean + tdur / nruns\n",
    "                if len(t) + 1 < minseg:\n",
    "                    minseg = len(t) + 1\n",
    "                if len(t) + 1 > maxseg:\n",
    "                    maxseg = len(t) + 1\n",
    "            \n",
    "            print(\"Delta = \" + str(delta) + \", alpha = \" + str(alpha) + \", beta = \" + str(beta) + \", \" + str(minseg) + \" minimum segments, \" + str(maxseg) + \" maximum segments on \" + \"{:.2}\".format(tmean) + \" seconds.\")\n",
    "                \n",
    "            res.append([delta, beta, alpha, nsegmean, minseg, maxseg, tdur])\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(res, columns = ['delta', 'beta', 'alpha', 'nsegmean', 'minseg', 'maxseg', 'tmean'])\n",
    "print(df[['delta', 'beta', 'minseg', 'maxseg', 'tmean']].to_latex(index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing $\\alpha = 0.5$, several values of $\\beta$\n",
    "\n",
    "Note: the cell below replicates the results reported on Table 4, p. 14 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "deltalist = [1, 1.1, 1.5]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 20000\n",
    "mcburn = 10000\n",
    "alphalist = [0.5]\n",
    "betalist = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "nruns = 30\n",
    "\n",
    "# replicate = True to replicate results\n",
    "ss = SeqSeg(replicate = True)\n",
    "res = []\n",
    "\n",
    "np.random.seed(123456)\n",
    "\n",
    "for delta in deltalist:\n",
    "    # Simulates signal\n",
    "    signal = np.random.normal(0, 1, [npoints, 1])\n",
    "    for i in range(len(cuts)):\n",
    "        if (i+1)%2:\n",
    "            signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta))\n",
    "    ss.feed_data(signal)\n",
    "    for beta in betalist:\n",
    "        for alpha in alphalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "            nsegmean = 0\n",
    "            minseg = 500000\n",
    "            maxseg = 0\n",
    "            tmean = 0\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 5000, res = 100, verbose = False)\n",
    "                nsegmean = nsegmean + (len(t)+1)/nruns\n",
    "                tmean = tmean + tdur / nruns\n",
    "                if len(t) + 1 < minseg:\n",
    "                    minseg = len(t) + 1\n",
    "                if len(t) + 1 > maxseg:\n",
    "                    maxseg = len(t) + 1\n",
    "            \n",
    "            print(\"Delta = \" + str(delta) + \", alpha = \" + str(alpha) + \", beta = \" + str(beta) + \", \" + str(minseg) + \" minimum segments, \" + str(maxseg) + \" maximum segments on \" + \"{:.2}\".format(tmean) + \" seconds.\")\n",
    "                \n",
    "            res.append([delta, beta, alpha, nsegmean, minseg, maxseg, tdur])\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(res, columns = ['delta', 'beta', 'alpha', 'nsegmean', 'minseg', 'maxseg', 'tmean'])\n",
    "print(df[['delta', 'beta', 'minseg', 'maxseg', 'tmean']].to_latex(index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing $\\alpha = 0.9$, several values of $\\beta$\n",
    "\n",
    "Note: the cell below replicates the results reported on Table 4, p. 14 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "deltalist = [1, 1.1, 1.5]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 20000\n",
    "mcburn = 10000\n",
    "alphalist = [0.9]\n",
    "betalist = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "nruns = 30\n",
    "\n",
    "# replicate = True to replicate results\n",
    "ss = SeqSeg(replicate = True)\n",
    "res = []\n",
    "\n",
    "np.random.seed(123456)\n",
    "\n",
    "for delta in deltalist:\n",
    "    # Simulates signal\n",
    "    signal = np.random.normal(0, 1, [npoints, 1])\n",
    "    for i in range(len(cuts)):\n",
    "        if (i+1)%2:\n",
    "            signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta))\n",
    "    ss.feed_data(signal)\n",
    "    for beta in betalist:\n",
    "        for alpha in alphalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "            nsegmean = 0\n",
    "            minseg = 500000\n",
    "            maxseg = 0\n",
    "            tmean = 0\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 5000, res = 100, verbose = False)\n",
    "                nsegmean = nsegmean + (len(t)+1)/nruns\n",
    "                tmean = tmean + tdur / nruns\n",
    "                if len(t) + 1 < minseg:\n",
    "                    minseg = len(t) + 1\n",
    "                if len(t) + 1 > maxseg:\n",
    "                    maxseg = len(t) + 1\n",
    "            \n",
    "            print(\"Delta = \" + str(delta) + \", alpha = \" + str(alpha) + \", beta = \" + str(beta) + \", \" + str(minseg) + \" minimum segments, \" + str(maxseg) + \" maximum segments on \" + \"{:.2}\".format(tmean) + \" seconds.\")\n",
    "                \n",
    "            res.append([delta, beta, alpha, nsegmean, minseg, maxseg, tdur])\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(res, columns = ['delta', 'beta', 'alpha', 'nsegmean', 'minseg', 'maxseg', 'tmean'])\n",
    "print(df[['delta', 'beta', 'minseg', 'maxseg', 'tmean']].to_latex(index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing $\\alpha = 0.99$, several values of $\\beta$\n",
    "\n",
    "Note: the cell below replicates the results reported on Table 4, p. 14 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "deltalist = [1, 1.1, 1.5]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 20000\n",
    "mcburn = 10000\n",
    "alphalist = [0.99]\n",
    "betalist = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "nruns = 30\n",
    "\n",
    "# replicate = True to replicate results\n",
    "ss = SeqSeg(replicate = True)\n",
    "res = []\n",
    "\n",
    "np.random.seed(123456)\n",
    "\n",
    "for delta in deltalist:\n",
    "    # Simulates signal\n",
    "    signal = np.random.normal(0, 1, [npoints, 1])\n",
    "    for i in range(len(cuts)):\n",
    "        if (i+1)%2:\n",
    "            signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta))\n",
    "    ss.feed_data(signal)\n",
    "    for beta in betalist:\n",
    "        for alpha in alphalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "            nsegmean = 0\n",
    "            minseg = 500000\n",
    "            maxseg = 0\n",
    "            tmean = 0\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 5000, res = 100, verbose = False)\n",
    "                nsegmean = nsegmean + (len(t)+1)/nruns\n",
    "                tmean = tmean + tdur / nruns\n",
    "                if len(t) + 1 < minseg:\n",
    "                    minseg = len(t) + 1\n",
    "                if len(t) + 1 > maxseg:\n",
    "                    maxseg = len(t) + 1\n",
    "            \n",
    "            print(\"Delta = \" + str(delta) + \", alpha = \" + str(alpha) + \", beta = \" + str(beta) + \", \" + str(minseg) + \" minimum segments, \" + str(maxseg) + \" maximum segments on \" + \"{:.2}\".format(tmean) + \" seconds.\")\n",
    "                \n",
    "            res.append([delta, beta, alpha, nsegmean, minseg, maxseg, tdur])\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(res, columns = ['delta', 'beta', 'alpha', 'nsegmean', 'minseg', 'maxseg', 'tmean'])\n",
    "print(df[['delta', 'beta', 'minseg', 'maxseg', 'tmean']].to_latex(index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration for a grid of $\\beta$ and $\\alpha$ with varying delta\n",
    "\n",
    "Note: the cells below replicate the results of figures 2 and 3, p. 17 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Signal characteristics\n",
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "delta = [1.1, 1, 1.5, 1, 1.2]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 10000\n",
    "mcburn = 10000\n",
    "\n",
    "# Alpha grid\n",
    "alphamin = 0.1\n",
    "alphamax = 0.1\n",
    "nstep = 0\n",
    "adelta = (alphamax - alphamin) / max(1, nstep)\n",
    "alphalist = [alphamin + d*adelta for d in range(nstep+1)]\n",
    "\n",
    "# Beta grid\n",
    "betamin = 1e-5\n",
    "betamax = 1e-3\n",
    "nstep = 100\n",
    "bdelta = (betamax - betamin) / max(1, nstep)\n",
    "betalist = [betamin + d*bdelta for d in range(nstep+1)]\n",
    "\n",
    "# To use union of two separate grids \n",
    "betamin = 1e-3\n",
    "betamax = 1e-1\n",
    "nstep = 100\n",
    "bdelta = (betamax - betamin) / max(1, nstep)\n",
    "betalist = betalist + [betamin + d*bdelta for d in range(nstep+1)]\n",
    "\n",
    "# Number of segmentations to run for each combination of parameters\n",
    "nruns = 1\n",
    "\n",
    "ss = SeqSeg(replicate = True)\n",
    "res = []\n",
    "\n",
    "# To replicate results \n",
    "np.random.seed(123456)\n",
    "\n",
    "# Simulates signal\n",
    "signal = np.random.normal(0, stdnoise, [npoints, 1])\n",
    "for i in range(len(cuts)-1):\n",
    "    signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta[i]))\n",
    "\n",
    "\n",
    "ss.feed_data(signal)        \n",
    "result = []\n",
    "tresult = []\n",
    "cont = 1\n",
    "ntotal = len(betalist)*len(alphalist)\n",
    "for alpha in alphalist:\n",
    "    for beta in betalist:\n",
    "        ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "        t, tdur = ss.segments(minlen = 5000, res = 1, verbose = False)\n",
    "        result.append([alpha, beta, len(t)+1])\n",
    "        #t.sort()\n",
    "        tresult.append(t)\n",
    "\n",
    "        print('({:.2%})'.format(cont/ntotal) + ' Alpha = {:.3}'.format(alpha) + ', Beta = {:.5}'.format(beta) + \", \" + str(len(t)+1) + \" segments\")\n",
    "        cont = cont + 1         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for figure 2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "figfolder = 'bayeseg/figures'\n",
    "plt.style.use('grayscale')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig = plt.figure(figsize = [12, 8])\n",
    "\n",
    "plot1 = fig.add_subplot(1,1,1)\n",
    "#plot1.plot([d[1] for d in result if d[1] < 0.001], [d[2] for d in result if d[1] < 0.001], marker = 'o')\n",
    "plot1.plot(betalist[:100], [len(t)+1 for t in tresult[:100]], marker = 'o')\n",
    "\n",
    "plt.ylim(0, 8)\n",
    "plt.xlim(min(betalist[:100]), max(betalist[:100]))\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Number of segments')\n",
    "plt.grid(linestyle = 'dotted')\n",
    "plt.savefig(figfolder + 'beta_results_1.pdf', dpi = 1000, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for figure 3\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "figfolder = 'bayeseg/figures'\n",
    "plt.style.use('grayscale')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig = plt.figure(figsize = [12, 8])\n",
    "\n",
    "plot1 = fig.add_subplot(1,1,1)\n",
    "#plot1.plot([d[1] for d in result if d[1] < 0.001], [d[2] for d in result if d[1] < 0.001], marker = 'o')\n",
    "plot1.plot(betalist[100:], [len(t)+1 for t in tresult[100:]], marker = 'o')\n",
    "\n",
    "plt.ylim(0, 8)\n",
    "plt.xlim(min(betalist[100:]), max(betalist[100:]))\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Number of segments')\n",
    "plt.grid(linestyle = 'dotted')\n",
    "plt.savefig(figfolder + 'beta_results_2.pdf', dpi = 1000, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration for a grid of $\\beta$ and $\\alpha$ with varying delta\n",
    "\n",
    "Note: the cells below replicate the results of figures 4, p. 18 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Signal characteristics\n",
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "delta = [1.1, 1, 1.5, 1, 1.2]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 10000\n",
    "mcburn = 10000\n",
    "\n",
    "# Alpha grid\n",
    "alphamin = 0.01\n",
    "alphamax = 0.99\n",
    "nstep = 100\n",
    "adelta = (alphamax - alphamin) / max(1, nstep)\n",
    "alphalist = [alphamin + d*adelta for d in range(nstep+1)]\n",
    "\n",
    "# Beta grid\n",
    "betamin = 0.1\n",
    "betamax = 0.1\n",
    "nstep = 0\n",
    "bdelta = (betamax - betamin) / max(1, nstep)\n",
    "betalist = [betamin + d*bdelta for d in range(nstep+1)]\n",
    "\n",
    "\n",
    "# Number of segmentations to run for each combination of parameters\n",
    "nruns = 1\n",
    "\n",
    "ss = SeqSeg(replicate = True)\n",
    "res = []\n",
    "\n",
    "# To replicate results \n",
    "np.random.seed(123456)\n",
    "\n",
    "# Simulates signal\n",
    "signal = np.random.normal(0, stdnoise, [npoints, 1])\n",
    "for i in range(len(cuts)-1):\n",
    "    signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta[i]))\n",
    "\n",
    "\n",
    "ss.feed_data(signal)        \n",
    "result = []\n",
    "tresult = []\n",
    "cont = 1\n",
    "ntotal = len(betalist)*len(alphalist)\n",
    "for alpha in alphalist:\n",
    "    for beta in betalist:\n",
    "        ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "        t, tdur = ss.segments(minlen = 5000, res = 1, verbose = False)\n",
    "        result.append([alpha, beta, len(t)+1])\n",
    "        #t.sort()\n",
    "        tresult.append(t)\n",
    "\n",
    "        print('({:.2%})'.format(cont/ntotal) + ' Alpha = {:.3}'.format(alpha) + ', Beta = {:.5}'.format(beta) + \", \" + str(len(t)+1) + \" segments\")\n",
    "        cont = cont + 1         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for figure 4\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "figfolder = 'bayeseg/figures/'\n",
    "plt.style.use('grayscale')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig = plt.figure(figsize = [12, 8])\n",
    "\n",
    "plot1 = fig.add_subplot(1,1,1)\n",
    "#plot1.plot([d[1] for d in result if d[1] < 0.001], [d[2] for d in result if d[1] < 0.001], marker = 'o')\n",
    "plot1.plot(alphalist, [len(t)+1 for t in tresult], marker = 'o')\n",
    "\n",
    "plt.ylim(4, 10)\n",
    "plt.xlim(min(alphalist), max(alphalist))\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Number of segments')\n",
    "plt.grid(linestyle = 'dotted')\n",
    "plt.savefig(figfolder + 'alpha_results.pdf', dpi = 1000, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the algorithm on real samples\n",
    "\n",
    "Note: the cells below replicate the results from Table 7, p. 21 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/paulo/github/bayeseg/Data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-175ec24bfc55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Creates object to read wave files and segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOceanPod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/bayeseg/OceanPod/OceanPod.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wav_folder)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Folder with waveforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwav_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiledt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiledt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/paulo/github/bayeseg/Data/'"
     ]
    }
   ],
   "source": [
    "from OceanPod.OceanPod import OceanPod \n",
    "\n",
    "\n",
    "wavfolder = '/bayeseg/Data/'\n",
    "savefolder = '/bayeseg/Output/'\n",
    "filelist = ['2015.01.30_02.02.56.wav', '2015.02.02_07.50.49.wav', '2015.02.08_11.26.39.wav']\n",
    "\n",
    "# Creates object to read wave files and segments\n",
    "op = OceanPod(wavfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC parameters\n",
    "\n",
    "mciter = 20000\n",
    "mcburn = 20000\n",
    "nchains = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta grid\n",
    "\n",
    "betamin = 5e-6\n",
    "betamax = 5e-5\n",
    "nstep = 6\n",
    "bdelta = (betamax - betamin) / max(nstep, 1)\n",
    "betalist = [betamin + d*bdelta for d in range(nstep+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha grid\n",
    "\n",
    "alphamin = 0.1\n",
    "alphamax = 0.1\n",
    "\n",
    "nstep = 0\n",
    "adelta = (alphamax - alphamin) / max(nstep, 1)\n",
    "alphalist = [alphamin + d*adelta for d in range(nstep+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "ss = SeqSeg(replicate = True)\n",
    "\n",
    "nruns = 1\n",
    "\n",
    "tresults = []\n",
    "results = []\n",
    "cont = 1\n",
    "total = len(filelist) * len(alphalist) * len(betalist)\n",
    "for file in filelist:\n",
    "    fs, wave = op.readFile(file)\n",
    "    ss.feed_data(wave)\n",
    "    for alpha in alphalist:\n",
    "        for beta in betalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains)\n",
    "            resiter = []\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 11025, res = 11025, verbose = False)\n",
    "                nseg = len(t) + 1\n",
    "                resiter.append([nseg, tdur])\n",
    "                tresults.append([file, t])\n",
    "            meannseg = np.mean([r[0] for r in resiter])\n",
    "            stdseg = np.std([r[0] for r in resiter])\n",
    "            tmean = np.mean([r[1] for r in resiter])\n",
    "            print(\"({:.4%})\".format(cont/total) + file + \", a = {:.2}\".format(alpha) + \", b = {:.6}\".format(beta) + \", Nseg = \" + str(meannseg) + \", Nsegstd = \" + str(stdseg) + \", t = {:.2}\".format(tmean))\n",
    "            cont = cont + 1\n",
    "            results.append([file, alpha, beta, meannseg, stdseg, tmean])\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Ample' : [r[0] for r in results], 'Beta' : [r[2] for r in results], 'Segments' : [r[3] for r in results], 'Time' : [r[5] for r in results]})\n",
    "print(df.to_latex(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 11\n",
    "\n",
    "betamin = 5e-6\n",
    "betamax = 5e-5\n",
    "nstep = 100\n",
    "bdelta = (betamax - betamin) / max(nstep, 1)\n",
    "betalist = [betamin + d*bdelta for d in range(nstep+1)]\n",
    "\n",
    "ss = SeqSeg(replicate = True)\n",
    "\n",
    "nruns = 1\n",
    "\n",
    "tresults = []\n",
    "results = []\n",
    "cont = 1\n",
    "total = len(filelist) * len(alphalist) * len(betalist)\n",
    "for file in filelist:\n",
    "    fs, wave = op.readFile(file)\n",
    "    ss.feed_data(wave)\n",
    "    for alpha in alphalist:\n",
    "        for beta in betalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains)\n",
    "            resiter = []\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 11025, res = 11025, verbose = False)\n",
    "                nseg = len(t) + 1\n",
    "                resiter.append([nseg, tdur])\n",
    "                tresults.append([file, t])\n",
    "            meannseg = np.mean([r[0] for r in resiter])\n",
    "            stdseg = np.std([r[0] for r in resiter])\n",
    "            tmean = np.mean([r[1] for r in resiter])\n",
    "            print(\"({:.4%})\".format(cont/total) + file + \", a = {:.2}\".format(alpha) + \", b = {:.6}\".format(beta) + \", Nseg = \" + str(meannseg) + \", Nsegstd = \" + str(stdseg) + \", t = {:.2}\".format(tmean))\n",
    "            cont = cont + 1\n",
    "            results.append([file, alpha, beta, meannseg, stdseg, tmean])\n",
    "\n",
    "df = pd.DataFrame({'s' : [r[0] for r in results], 'beta' : [r[2] for r in results], 'seg' : [r[3] for r in results]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for figure 4\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "figfolder = '/home/paulo/Google Drive/PhD/Trabalhos/FastImplCalibr/JSS/bayeseg/'\n",
    "plt.style.use('grayscale')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig = plt.figure(figsize = [15, 15])\n",
    "\n",
    "plot1 = fig.add_subplot(3,1,1)\n",
    "plot1.plot(betalist, df.loc[df.s == '2015.01.30_02.02.56.wav', 'seg'], marker = 'o')\n",
    "plot1.set_title('2015.01.30_02.02.56.wav')\n",
    "plt.grid(linestyle = 'dotted')\n",
    "plt.ylim(0, 5)\n",
    "plt.xlim(min(betalist), max(betalist))\n",
    "\n",
    "plot2 = fig.add_subplot(3,1,2)\n",
    "plot2.plot(betalist, df.loc[df.s == '2015.02.02_07.50.49.wav', 'seg'], marker = 'o')\n",
    "plot2.set_title('2015.02.02_07.50.49.wav')\n",
    "plt.grid(linestyle = 'dotted')\n",
    "plt.ylim(0, 12)\n",
    "plt.xlim(min(betalist), max(betalist))\n",
    "\n",
    "plot3 = fig.add_subplot(3,1,3)\n",
    "plot3.plot(betalist, df.loc[df.s == '2015.02.08_11.26.39.wav', 'seg'], marker = 'o')\n",
    "plot3.set_title('2015.02.08_11.26.39.wav')\n",
    "plt.ylim(0, 35)\n",
    "plt.xlim(min(betalist), max(betalist))\n",
    "\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Number of segments')\n",
    "plt.grid(linestyle = 'dotted')\n",
    "plt.savefig(figfolder + 'alpha_beta_all_sig.pdf', dpi = 1000, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final segmentation\n",
    "\n",
    "Note: the cell below output files \"20150202.csv\" and \"20150208.csv\", with the segmentation points that are used on figures 9 and 10, p. 23 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OceanPod.OceanPod import OceanPod \n",
    "\n",
    "\n",
    "wavfolder = '/home/paulo/git/bayeseg/Data/'\n",
    "savefolder = '/home/paulo/git/bayeseg/Output/'\n",
    "filelist = ['2015.01.30_02.02.56.wav', '2015.02.02_07.50.49.wav', '2015.02.08_11.26.39.wav']\n",
    "\n",
    "# Creates object to read wave files and segments\n",
    "op = OceanPod(wavfolder)\n",
    "ss = SeqSeg(replicate = True)\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.1\n",
    "mciter = 20000\n",
    "mcburn = 10000\n",
    "nchains = 1\n",
    "\n",
    "\n",
    "# 2015-02-02\n",
    "beta = 9.5e-06\n",
    "\n",
    "file = filelist[1]\n",
    "fs, wave = op.read_file(file)\n",
    "ss.feed_data(wave)\n",
    "ss.initialize(beta, alpha, mciter, mcburn, nchains)\n",
    "t, tdur = ss.segments(minlen = 11025, res = 11025, verbose = False)\n",
    "nseg = len(t) + 1\n",
    "\n",
    "# Creating file\n",
    "with open(wavfolder + '20150202.csv', 'w') as arq:\n",
    "    arq.write(\",\".join([str(i) for i in t]))\n",
    "    \n",
    "\n",
    "# 2015-02-08    \n",
    "beta = 3.11e-05\n",
    "\n",
    "file = filelist[2]\n",
    "fs, wave = op.read_file(file)\n",
    "ss.feed_data(wave)\n",
    "ss.initialize(beta, alpha, mciter, mcburn, nchains)\n",
    "t, tdur = ss.segments(minlen = 11025, res = 11025, verbose = False)\n",
    "nseg = len(t) + 1\n",
    "\n",
    "# Creating file\n",
    "with open(wavfolder + '20150208.csv', 'w') as arq:\n",
    "    arq.write(\",\".join([str(i) for i in t]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
